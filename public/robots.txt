# robots.txt for Namami Enterprises
# https://namamienterprises.in/robots.txt

# Allow all search engines to crawl everything by default
User-agent: *
Allow: /

# Block specific paths (if any - currently allowing all)
# Disallow: /admin/
# Disallow: /api/
# Disallow: /private/

# Crawl-delay for polite crawling (optional)
# Crawl-delay: 1

# Specific rules for major search engines

# Google Bot
User-agent: Googlebot
Allow: /
Crawl-delay: 0

# Google Image Bot
User-agent: Googlebot-Image
Allow: /

# Google Mobile Bot
User-agent: Googlebot-Mobile
Allow: /

# Bing Bot
User-agent: Bingbot
Allow: /
Crawl-delay: 0

# Yandex Bot
User-agent: Yandex
Allow: /
Crawl-delay: 2

# Baidu Bot (Chinese search engine)
User-agent: Baiduspider
Allow: /
Crawl-delay: 2

# DuckDuckGo Bot
User-agent: DuckDuckBot
Allow: /

# Block bad bots and scrapers
User-agent: AhrefsBot
Disallow: /

User-agent: SemrushBot
Disallow: /

User-agent: DotBot
Disallow: /

User-agent: MJ12bot
Disallow: /

User-agent: BLEXBot
Disallow: /

User-agent: PetalBot
Disallow: /

# Sitemap location (IMPORTANT: Update this after creating sitemap.xml)
Sitemap: https://namamienterprises.in/sitemap.xml
Sitemap: https://namamienterprises.in/sitemap-products.xml
Sitemap: https://namamienterprises.in/sitemap-pages.xml

# Host specification (helps with canonical URL)
Host: namamienterprises.in